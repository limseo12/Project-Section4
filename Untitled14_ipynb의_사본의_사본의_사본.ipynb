{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb의 사본의 사본의 사본",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP6TWq0/TGUX8s4K2yCNjZi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limseo12/Project-Section4/blob/main/Untitled14_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **표지판 이미지 불러오기**"
      ],
      "metadata": {
        "id": "2VMQwCKQjwVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Onivoj7DjCya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 가져오기"
      ],
      "metadata": {
        "id": "SsWQocDAnEER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from os import getcwd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPool2D,BatchNormalization"
      ],
      "metadata": {
        "id": "tFkEQcV-nUge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = \"../input/content/drive/MyDrive/section4_Project/Train/\"\n",
        "path_test = \"../input/drive/MyDrive/section4_Project/Test/\"\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/section4_Project/Train.csv\")\n",
        "\n",
        "height = 50\n",
        "width = 50\n",
        "channels = 3\n",
        "classes = 43\n",
        "n_inputs = height * width*channels"
      ],
      "metadata": {
        "id": "VHn0qdo82G3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def path_to_img(input_path):\n",
        "    data=[]\n",
        "    labels=[]\n",
        "    for i in range(classes):\n",
        "        path = input_path + '{0}/'.format(i)\n",
        "        Class = os.listdir(path)\n",
        "        for a in Class:\n",
        "            try:\n",
        "                image=cv2.imread(path+a)\n",
        "                image_from_array = Image.fromarray(image, 'RGB')\n",
        "                size_image = image_from_array.resize((height,width))\n",
        "                data.append(np.array(size_image))\n",
        "                labels.append(i)\n",
        "            except AttributeError:\n",
        "                print(\" \")\n",
        "    return np.array(data), np.array(labels)\n",
        "            \n",
        "images_train, labels_train = path_to_img(path_train)\n",
        "\n",
        "print(images_train.shape)\n",
        "print(labels_train.shape)"
      ],
      "metadata": {
        "id": "16S8kTNu4jo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지를 읽어와서 배열에 넣기"
      ],
      "metadata": {
        "id": "PeB3Y_XYoFmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 검증 세트로 분할"
      ],
      "metadata": {
        "id": "JHxSiL-brbX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(images_train, labels_train, test_size=0.9)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_valid = X_valid.astype('float32')/255\n",
        "\n",
        "y_train = to_categorical(y_train,43)\n",
        "y_valid = to_categorical(y_valid,43)"
      ],
      "metadata": {
        "id": "HPTeuW-4rixq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 신경망 구성 CNN"
      ],
      "metadata": {
        "id": "XPZ-d7tIu7PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (5,5), activation='relu', input_shape=(50,50,3)),\n",
        "    Conv2D(32, (3,3)),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    Conv2D(64, (3,3)),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    MaxPool2D(2,2),\n",
        "    #Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(256),\n",
        "    BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "gkHAYsosvCje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 트레이닝"
      ],
      "metadata": {
        "id": "fuyQSpgFxxLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "epochs = 15\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_valid,y_valid)\n",
        ")"
      ],
      "metadata": {
        "id": "QcaPAyLJxzi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정확도, 손실 표시"
      ],
      "metadata": {
        "id": "RT5O3A5qyVMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(acc, 'r', label='Training accuracy')\n",
        "plt.plot(val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(loss, 'r', label='Training loss')\n",
        "plt.plot(val_loss, 'b', label='Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eqYynSAOyLrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트 데이터 예측"
      ],
      "metadata": {
        "id": "-_PSsgCBzS31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = pd.read_csv(\"/content/drive/MyDrive/section4_Project/Test.csv\")\n",
        "labels = y_test['Path'].values\n",
        "y_test = y_test['ClassId'].values\n",
        "\n",
        "\n",
        "data = []\n",
        "\n",
        "for f in labels:\n",
        "    image = cv2.imread(path_test + f.replace('Test/', ''))\n",
        "    image_from_array = Image.fromarray(image, 'RGB')\n",
        "    size_image = image_from_array.resize((height, width))\n",
        "    data.append(np.array(size_image))\n",
        "    \n",
        "X_test = np.array(data)\n",
        "X_test = X_test.astype('float32')/255\n",
        "predict_x=model.predict(X_test) \n",
        "classes_x=np.argmax(predict_x,axis=-1)"
      ],
      "metadata": {
        "id": "UyVn5LQvzdvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정확도"
      ],
      "metadata": {
        "id": "zgxAo6dn0jLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, classes_x)"
      ],
      "metadata": {
        "id": "gY887xRD0xS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다른모델 해보기"
      ],
      "metadata": {
        "id": "l4bMPgITz2Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vggnet"
      ],
      "metadata": {
        "id": "wVe0kwhb0Ozp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
        "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)"
      ],
      "metadata": {
        "id": "MLmB_GT0z4mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "img_size = 32\n",
        "\n",
        "# 첫 번째 Conv Block\n",
        "# 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
        "model.add(Input((img_size, img_size, 3)))\n",
        "model.add(conv(64))\n",
        "model.add(conv(64))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 두 번째 Conv Block\n",
        "model.add(conv(128))\n",
        "model.add(conv(128))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 세 번째 Conv Block\n",
        "model.add(conv(256))\n",
        "model.add(conv(256))\n",
        "model.add(conv(256))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 네 번째 Conv Block\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 다섯 번째 Conv Block\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
        "model.add(keras.layers.Dense(58, activation= tf.nn.softmax))\n",
        "  \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hNFoiqD1z_ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet 정확도 :"
      ],
      "metadata": {
        "id": "TZ29k3cu0GxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
        "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  img_size = 512\n",
        "\n",
        "  # Sequential 모델 선언\n",
        "  model = keras.Sequential()\n",
        "    \n",
        "  '''\n",
        "  지시사항 1번\n",
        "  3 x 3 convolution만을 사용하여 VGG16 Net을 완성하세요.\n",
        "  '''\n",
        "  # 첫 번째 Conv Block\n",
        "  # 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
        "  model.add(Input((img_size, img_size, 3)))\n",
        "  model.add(conv(64))\n",
        "  model.add(conv(64))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 두 번째 Conv Block\n",
        "  model.add(conv(128))\n",
        "  model.add(conv(128))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 세 번째 Conv Block\n",
        "  model.add(conv(256))\n",
        "  model.add(conv(256))\n",
        "  model.add(conv(256))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 네 번째 Conv Block\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 다섯 번째 Conv Block\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # Fully Connected Layer\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(58, activation= tf.nn.softmax))\n",
        "\n",
        "  train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(512)\n",
        "\n",
        "  print(train_images.shape)\n",
        "  print(type(train_images))\n",
        "  \n",
        "  \n",
        "  # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
        "  model = VGG16(512)\n",
        "  \n",
        "  # 모델의 구조를 확인합니다.\n",
        "  model.summary()\n",
        "  \n",
        "  # 컴파일러를 설정합니다.\n",
        "  optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "  model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  \n",
        "  # fit 함수를 사용하여 모델을 학습합니다.\n",
        "  # 학습 수행 시 정보는 history에 저장합니다.\n",
        "  history = model.fit(train_images,train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels), verbose = 2)\n",
        "  \n",
        "  # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
        "  loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
        "  \n",
        "  print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
        "  print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
        "  \n",
        "  Visualize([('VGGNet', history)], 'loss')\n",
        "    \n",
        "  Plotter(test_images, model)"
      ],
      "metadata": {
        "id": "ayoIdCQm0B_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}