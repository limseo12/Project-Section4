{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled18.ipynb의 사본",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP1gh/z55Mhw8D4kBGLjRI1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limseo12/Project-Section4/blob/main/Untitled18_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aafb9KBXiS03"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "s6SSWG5WvyAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위의 코드를 처음 부분에 넣어주면 GPU 아래의 모든 부분에 대해 GPU로 실행하도록 한다.\n",
        "#이 때 os.environ[\"CUDA_VISIBLE_DEVICES\"]에 사용하고자 하는 GPU의 넘버를 적어주면 된다\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "0Ormxun0wXm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 데이터 분석"
      ],
      "metadata": {
        "id": "RcRV5i6CwaNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##구글 드라이브 압축파일을 풀어주는 코드 작성 \n",
        "## %cd 압축을 풀 경로 !unzip -qq \"압축파일 Path\"\n",
        "## %cd /content/drive/MyDrive/section4_Project\n",
        "## !unzip -qq \"/content/drive/MyDrive/German-Traffic-sign.zip\""
      ],
      "metadata": {
        "id": "2LRDLnvfw-1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##압축이 잘 풀렸는지 확인하는 함수 glob. import해줘야한다\n",
        "from glob import *\n",
        "filepaths = list(glob('/content/drive/MyDrive/section4_Project/*.png'))\n",
        "len(filepaths)"
      ],
      "metadata": {
        "id": "x8g7RZlTxhpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 이미지 데이터 정보 확인\n",
        "DATA_PATH = '/content/drive/MyDrive/section4_Project'\n",
        "file_list = os.listdir(DATA_PATH)\n",
        "file_list"
      ],
      "metadata": {
        "id": "o_lHQTeEzOsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta 파일은 레이블당 하나의 샘플 이미지를 보여주는 파일이다"
      ],
      "metadata": {
        "id": "7OPIweepzhcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Meta = pd.read_csv('/content/drive/MyDrive/section4_Project/Meta.csv')\n",
        "df_Meta"
      ],
      "metadata": {
        "id": "x9cwpbQ0zfkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Meta_images = []\n",
        "Meta_labels = []\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(len(df_Meta)):\n",
        "  img = load_img(df_Meta['Path'][i])\n",
        "  plt.subplot(7, 7, i+1)\n",
        "  plt.imshow(img)\n",
        "  Meta_images.append(img)\n",
        "  Meta_labels.append(df_Meta['ClassId'])"
      ],
      "metadata": {
        "id": "0229YYwQzufJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "z-pUcGH40Kyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train = pd.read_csv('/content/drive/MyDrive/section4_Project/Train.csv')\n",
        "df_Train"
      ],
      "metadata": {
        "id": "AG8pCWFF0Jeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = pd.cut(df_Train['Width'], np.arange(0,200,10)).value_counts(sort=False)\n",
        "plt.bar(dist.index.astype(str), dist.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "dist"
      ],
      "metadata": {
        "id": "EqK9C73T0iKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 사이즈"
      ],
      "metadata": {
        "id": "4Y-nI_Gm5BHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_height = 32\n",
        "image_width = 32\n",
        "image_channel = 3 #컬러 이미지가 있어서 3채널"
      ],
      "metadata": {
        "id": "yjXL2axi1uh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "IShfGiSP5Hcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test = pd.read_csv('/content/drive/MyDrive/section4_Project/Test.csv')\n",
        "df_Test"
      ],
      "metadata": {
        "id": "gh25m-hy3jRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리"
      ],
      "metadata": {
        "id": "oj-UR5h65J3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train"
      ],
      "metadata": {
        "id": "zQCnycDf5Ppv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train['ClassId'] = df_Train['ClassId'].astype(str)\n",
        "df_Test['ClassId'] = df_Test['ClassId'].astype(str)"
      ],
      "metadata": {
        "id": "VokUNRSw50mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test size\n",
        "# 0.2 : test accuracy 96.5%\n",
        "# 0.4 : test accuracy 91.5%"
      ],
      "metadata": {
        "id": "3SrwaLum6FZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train, df_Valid = train_test_split(df_Train, test_size=0.2)\n",
        "df_Train"
      ],
      "metadata": {
        "id": "x-T3FSU76Bay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Valid"
      ],
      "metadata": {
        "id": "Q-hqLYW76JAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data augmentation\n",
        "기본 : test accuracy 87.8%, 33ms/step\n",
        "+ brightness_range : test accuracy 88.8%, 33ms/step\n",
        "+ zoom_range 0.2 / rotation_range 20 : test accuracy 96.5%\n",
        "+ zoom_range=0.2 (전체) / shear_range=0.2 : test accuracy 92.5%"
      ],
      "metadata": {
        "id": "4rYsgw7Y6UkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen_kwargs = dict(rescale=1./255)\n",
        "dataflow_kwargs = dict(target_size=(image_height, image_width), \n",
        "                       batch_size=16,\n",
        "                       directory=DATA_PATH, \n",
        "                       x_col='Path', \n",
        "                       y_col='ClassId' ,\n",
        "                       class_mode='sparse',\n",
        "                       interpolation='bilinear',\n",
        "                       brightness_range=[0.9,1.3]\n",
        "                      )\n",
        "\n",
        "##이미지를 사용할 때마다 임의로 변형을 가함으로써 마치 훨씬 더 많은 이미지를 보고 공부하는 것과 같은 학습 효과를 낸다.\n",
        "##이를 통해 과적합(overfitting), 즉 모델이 학습 데이터에만 맞춰지는 것을 방지하고, 새로운 이미지도 잘 분류할 수 있게 됨.\n",
        "##이런 전처리 과정을 돕기 위해 케라스는 ImageDataGenerator 클래스를 제공\n",
        "# Train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    zoom_range = 0.2,\n",
        "    **datagen_kwargs\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        df_Train, \n",
        "        **dataflow_kwargs\n",
        ")\n",
        "\n",
        "# Validation\n",
        "valid_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    df_Valid, \n",
        "    shuffle=False, \n",
        "    **dataflow_kwargs\n",
        ")\n",
        "\n",
        "# Test\n",
        "test_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    df_Test, \n",
        "    shuffle=False, \n",
        "    **dataflow_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "OhrpNYj06Yhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 딥러닝 모델\n",
        "3-1. CNN 모델 설정\n",
        "마지막에서 두 번째 Dense units=512 : test accuracy 88.8%, 33ms/step\n",
        "마지막에서 두 번째 Dense units=128 : test accuracy 88.8%, 22ms/step\n",
        "\n",
        "Conv + Pooling 세 층 : test accuracy 88.8%\n",
        "Conv + Pooling 두 층 : test accuracy 88.8%\n",
        "Conv + Pooling 한 층 : test accuracy 86.15%"
      ],
      "metadata": {
        "id": "VyvPjeR86e9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input((image_height, image_width, image_channel)),\n",
        "    Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    \n",
        "    Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(rate=0.25),\n",
        "    Dense(43, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JRioolk06g0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-2. 학습 수행\n",
        "optimizer\n",
        "SGD : test accuracy 88.8%\n",
        "Momentum 0.9 : test accuracy 95.6%\n",
        "Adam : test accuracy 5.9%"
      ],
      "metadata": {
        "id": "6TDde3-a6p55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "JXi_oCXy6sFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "# 처음 만든 모델이라면 EPOCHS를 1~5개로 하여 잘 돌아가는지 \n",
        "# 성능을 확인해보고 값을 증가 시켜 봅시다.\n",
        "# EPOCHS에 따른 성능을 보기 위하여 history 사용\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      validation_data = valid_generator, # validation 데이터 사용\n",
        "      epochs= EPOCHS    ##5~20 까지 변경해보기\n",
        "  )"
      ],
      "metadata": {
        "id": "R4mG0O5j6uZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Keras에서는 모델 학습을 위해 fit() 함수를 사용합니다.\n",
        "##이 때, 리턴값으로 학습 이력(History) 정보를 리턴합니다.\n",
        "##여기에는 다음과 같은 항목들이 포함되어 있습니다.\n",
        "##아래 항목들은 매 epoch 마다의 값들이 저장되어 있습니다.\n",
        "##loss : 훈련 손실값\n",
        "##acc : 훈련 정확도\n",
        "##val_loss : 검증 손실값\n",
        "##val_acc : 검증 정확도\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AUzITd5M6xpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train data보다 valid data의 정확도가 떨어지는 이유 ?\n",
        "train data의 경우 data augmentation를 적용하기 때문에 데이터에 무작위 변환을 하면 분류하기가 더 어려워 질 수 있다.\n",
        "\n",
        "3-3. 모델 성능 평가 및 예측"
      ],
      "metadata": {
        "id": "_Ee9SgOn6y8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print('test set accuracy: ', test_accuracy)"
      ],
      "metadata": {
        "id": "nH2kp4qt6yDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (13, 13))\n",
        "x_test, y_test = test_generator.next()\n",
        "pred_test = model.predict_on_batch(x_test)\n",
        "pred_class = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "start_index = 0\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    prediction = pred_class[start_index + i]\n",
        "    actual = int(y_test[start_index + i])\n",
        "    col = 'g'\n",
        "    if prediction != actual:\n",
        "        col = 'r'\n",
        "    plt.xlabel('Actual={} || Pred={}'.format(actual, prediction), color = col)\n",
        "    plt.imshow(array_to_img(x_test[start_index + i]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFseSCk962ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = model.predict(test_generator)\n",
        "predicted_class = np.argmax(test_prediction, axis=-1)"
      ],
      "metadata": {
        "id": "ifjN4YjG64OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(test_generator.labels, predicted_class)\n",
        "plt.figure(figsize = (20, 20))\n",
        "sns.heatmap(cm, annot = True)\n",
        "plt.show()\n",
        "print(classification_report(test_generator.labels, predicted_class))"
      ],
      "metadata": {
        "id": "27pSquoy65mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. VGGNet"
      ],
      "metadata": {
        "id": "ka7l1f_X68zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
        "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)"
      ],
      "metadata": {
        "id": "RVyWJPbA66pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "img_size = 32\n",
        "\n",
        "# 첫 번째 Conv Block\n",
        "# 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
        "model.add(Input((img_size, img_size, 3)))\n",
        "model.add(conv(64))\n",
        "model.add(conv(64))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 두 번째 Conv Block\n",
        "model.add(conv(128))\n",
        "model.add(conv(128))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 세 번째 Conv Block\n",
        "model.add(conv(256))\n",
        "model.add(conv(256))\n",
        "model.add(conv(256))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 네 번째 Conv Block\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 다섯 번째 Conv Block\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
        "model.add(keras.layers.Dense(58, activation= tf.nn.softmax))\n",
        "  \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dreMm3gu6-u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. ResNet\n",
        "정확도 :"
      ],
      "metadata": {
        "id": "KgtSMGAH7CaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
        "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  img_size = 512\n",
        "\n",
        "  # Sequential 모델 선언\n",
        "  model = keras.Sequential()\n",
        "    \n",
        "  '''\n",
        "  지시사항 1번\n",
        "  3 x 3 convolution만을 사용하여 VGG16 Net을 완성하세요.\n",
        "  '''\n",
        "  # 첫 번째 Conv Block\n",
        "  # 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
        "  model.add(Input((img_size, img_size, 3)))\n",
        "  model.add(conv(64))\n",
        "  model.add(conv(64))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 두 번째 Conv Block\n",
        "  model.add(conv(128))\n",
        "  model.add(conv(128))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 세 번째 Conv Block\n",
        "  model.add(conv(256))\n",
        "  model.add(conv(256))\n",
        "  model.add(conv(256))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 네 번째 Conv Block\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 다섯 번째 Conv Block\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # Fully Connected Layer\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(58, activation= tf.nn.softmax))\n",
        "\n",
        "  train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(512)\n",
        "\n",
        "  print(train_images.shape)\n",
        "  print(type(train_images))\n",
        "  \n",
        "  \n",
        "  # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
        "  model = VGG16(512)\n",
        "  \n",
        "  # 모델의 구조를 확인합니다.\n",
        "  model.summary()\n",
        "  \n",
        "  # 컴파일러를 설정합니다.\n",
        "  optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "  model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  \n",
        "  # fit 함수를 사용하여 모델을 학습합니다.\n",
        "  # 학습 수행 시 정보는 history에 저장합니다.\n",
        "  history = model.fit(train_images,train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels), verbose = 2)\n",
        "  \n",
        "  # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
        "  loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
        "  \n",
        "  print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
        "  print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
        "  \n",
        "  Visualize([('VGGNet', history)], 'loss')\n",
        "    \n",
        "  Plotter(test_images, model)"
      ],
      "metadata": {
        "id": "ixGp4_-u7Dqz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}