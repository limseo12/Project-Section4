{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb의 사본의 사본",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOnGlxREcfOKLzf4PX/M5gp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limseo12/Project-Section4/blob/main/Untitled14_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **표지판 이미지 불러오기**"
      ],
      "metadata": {
        "id": "2VMQwCKQjwVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Onivoj7DjCya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 가져오기"
      ],
      "metadata": {
        "id": "SsWQocDAnEER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "mQoqIrTHmvKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import style"
      ],
      "metadata": {
        "id": "tFkEQcV-nUge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "## 코드설명\n",
        "from IPython.core.display import HTML\n",
        "## 코드설명"
      ],
      "metadata": {
        "id": "jrxHr_RRnoQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "## 영상처리에 사용하는 오픈소스 라이브러리, 컴퓨터가 사람 눈처럼 인식할 수 있게 처리\n",
        "from PIL import Image\n",
        "## 파이썬 이미지 처리 pillow 라이브러리\n",
        "import os\n",
        "## 설명\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#imagedatagenerater는 이미지를 학습시킬 때 학습 데이터의 양이 적을 경우 학습데이터를 조금씩 변형 시켜서 학습데이터의 양을 늘리는 방식중 하나"
      ],
      "metadata": {
        "id": "gJ60Qzwgnu6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('/content/drive/MyDrive/section4_Project/Meta')\n",
        "train_path = pathlib.Path('/content/drive/MyDrive/section4_Project/Train')\n",
        "test_path = pathlib.Path('/content/drive/MyDrive/section4_Project/Test.csv')"
      ],
      "metadata": {
        "id": "VHn0qdo82G3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리 수 확인\n",
        "NUM_CATEGORIES = len(os.listdir(train_path))\n",
        "NUM_CATEGORIES"
      ],
      "metadata": {
        "id": "16S8kTNu4jo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지를 읽어와서 배열에 넣기"
      ],
      "metadata": {
        "id": "PeB3Y_XYoFmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "\n",
        "# 전처리: 이미지 별로 사이즈가 다르기 때문에 이미지의 폭과 높이를 같은 크기로 통일\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "classes = 43\n",
        "n_inputs = height * width * channels\n",
        "\n",
        "for i in range(classes) :\n",
        "  path= \"../input/train/{0}/\".format(i)\n",
        "  print(path)\n",
        "  Class=os.listdir(data_dir)\n",
        "  for a in Class :\n",
        "      try:\n",
        "        image = cv2.imread(path+a)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((height, width))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(i)\n",
        "      except AttributeError:\n",
        "        print(\" \")\n",
        "\n",
        "Cells=np.array(data)\n",
        "labels=np.array(labels)\n",
        "\n",
        "#순서 무작위\n",
        "s=np.arange(Cells.shape[0])\n",
        "np.random.seed(43)\n",
        "np.random.shuffle(s)\n",
        "Cells=Cells[s]\n",
        "labels=labels[s]\n"
      ],
      "metadata": {
        "id": "YUIFQw18n5Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 검증 세트로 분할"
      ],
      "metadata": {
        "id": "JHxSiL-brbX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\n",
        "##정규화\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_val = X_val.astype('float32')/255\n",
        "(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n",
        "\n",
        "##인코딩\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "#y_train = to_categorical(y_train, 43)\n",
        "#y_val = to_categorical(y_val, 43)"
      ],
      "metadata": {
        "id": "HPTeuW-4rixq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 신경망 구성 CNN"
      ],
      "metadata": {
        "id": "XPZ-d7tIu7PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape= (width,height,channels)))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#Compilation of the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "gkHAYsosvCje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 트레이닝"
      ],
      "metadata": {
        "id": "fuyQSpgFxxLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
        "validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "QcaPAyLJxzi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정확도, 손실 표시"
      ],
      "metadata": {
        "id": "RT5O3A5qyVMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['acc'], label= 'training accuracy')\n",
        "plt.plot(history.history['val_acc'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "eqYynSAOyLrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트 데이터 예측"
      ],
      "metadata": {
        "id": "-_PSsgCBzS31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=pd.read_csv(\"../input/Test.csv\")\n",
        "labels=y_test['Path'].as_matrix()\n",
        "y_test=y_test['classld'].values\n",
        "\n",
        "data=[]\n",
        "\n",
        "for f in labels:\n",
        "  image=cv2. imread('../input/test/'+f.replace('Test/',''))\n",
        "  image_from_array = image.fromarray(image, 'RGB')\n",
        "  size_image = image_from_array.resize((height, width))\n",
        "  data.append(np.array(size_image))\n",
        "\n",
        "X_test=np.array(data)\n",
        "X_test=X_test.astype('float32')/255\n",
        "pred = model.predict_classes(X_test)"
      ],
      "metadata": {
        "id": "UyVn5LQvzdvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정확도"
      ],
      "metadata": {
        "id": "zgxAo6dn0jLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "id": "gY887xRD0xS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다른모델 해보기"
      ],
      "metadata": {
        "id": "l4bMPgITz2Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vggnet"
      ],
      "metadata": {
        "id": "wVe0kwhb0Ozp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
        "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)"
      ],
      "metadata": {
        "id": "MLmB_GT0z4mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "img_size = 32\n",
        "\n",
        "# 첫 번째 Conv Block\n",
        "# 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
        "model.add(Input((img_size, img_size, 3)))\n",
        "model.add(conv(64))\n",
        "model.add(conv(64))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 두 번째 Conv Block\n",
        "model.add(conv(128))\n",
        "model.add(conv(128))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 세 번째 Conv Block\n",
        "model.add(conv(256))\n",
        "model.add(conv(256))\n",
        "model.add(conv(256))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 네 번째 Conv Block\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# 다섯 번째 Conv Block\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(conv(512))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
        "model.add(keras.layers.Dense(58, activation= tf.nn.softmax))\n",
        "  \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hNFoiqD1z_ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet 정확도 :"
      ],
      "metadata": {
        "id": "TZ29k3cu0GxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(filters, kernel_size = 3, activation= tf.nn.relu, padding= 'same'):\n",
        "    return keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, activation= activation, padding= padding)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  img_size = 512\n",
        "\n",
        "  # Sequential 모델 선언\n",
        "  model = keras.Sequential()\n",
        "    \n",
        "  '''\n",
        "  지시사항 1번\n",
        "  3 x 3 convolution만을 사용하여 VGG16 Net을 완성하세요.\n",
        "  '''\n",
        "  # 첫 번째 Conv Block\n",
        "  # 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다\n",
        "  model.add(Input((img_size, img_size, 3)))\n",
        "  model.add(conv(64))\n",
        "  model.add(conv(64))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 두 번째 Conv Block\n",
        "  model.add(conv(128))\n",
        "  model.add(conv(128))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 세 번째 Conv Block\n",
        "  model.add(conv(256))\n",
        "  model.add(conv(256))\n",
        "  model.add(conv(256))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 네 번째 Conv Block\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # 다섯 번째 Conv Block\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(conv(512))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  \n",
        "  # Fully Connected Layer\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(512, activation= tf.nn.relu))\n",
        "  model.add(keras.layers.Dense(58, activation= tf.nn.softmax))\n",
        "\n",
        "  train_images, test_images, train_labels, test_labels = get_images_and_preprocessing(512)\n",
        "\n",
        "  print(train_images.shape)\n",
        "  print(type(train_images))\n",
        "  \n",
        "  \n",
        "  # 지시사항 2에서 설정한 모델을 불러옵니다.\n",
        "  model = VGG16(512)\n",
        "  \n",
        "  # 모델의 구조를 확인합니다.\n",
        "  model.summary()\n",
        "  \n",
        "  # 컴파일러를 설정합니다.\n",
        "  optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "  model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  \n",
        "  # fit 함수를 사용하여 모델을 학습합니다.\n",
        "  # 학습 수행 시 정보는 history에 저장합니다.\n",
        "  history = model.fit(train_images,train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels), verbose = 2)\n",
        "  \n",
        "  # evaluate 함수를 사용하여 테스트 데이터의 결과값을 저장합니다.\n",
        "  loss, test_acc = model.evaluate(test_images,test_labels, verbose=2)\n",
        "  \n",
        "  print('\\nTest Loss : {:.4f} | Test Accuracy : {}'.format(loss, test_acc))\n",
        "  print('예측한 Test Data 클래스 : ',model.predict_classes(test_images))\n",
        "  \n",
        "  Visualize([('VGGNet', history)], 'loss')\n",
        "    \n",
        "  Plotter(test_images, model)"
      ],
      "metadata": {
        "id": "ayoIdCQm0B_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}